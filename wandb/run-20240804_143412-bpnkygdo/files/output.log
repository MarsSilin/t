  0%|          | 0/834 [00:00<?, ?it/s]You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
c:\ml_proj\tink_stag\.venv\Lib\site-packages\transformers\tokenization_utils_base.py:2906: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
  warnings.warn(
c:\ml_proj\tink_stag\.venv\Lib\site-packages\torch\utils\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Could not estimate the number of tokens of the input, floating-point operations will not be computed







  1%|          | 10/834 [00:17<23:24,  1.70s/it]








  2%|▏         | 19/834 [00:32<22:59,  1.69s/it]









  4%|▎         | 30/834 [00:51<23:33,  1.76s/it]









  5%|▍         | 40/834 [01:09<22:50,  1.73s/it]









  6%|▌         | 50/834 [01:26<23:26,  1.79s/it]








  7%|▋         | 60/834 [01:43<21:31,  1.67s/it]








  8%|▊         | 69/834 [01:58<21:53,  1.72s/it]









 10%|▉         | 80/834 [02:17<20:37,  1.64s/it]









 11%|█         | 90/834 [02:35<22:09,  1.79s/it]








 12%|█▏        | 100/834 [02:52<20:40,  1.69s/it]








 13%|█▎        | 110/834 [03:10<21:30,  1.78s/it]









 14%|█▍        | 120/834 [03:27<20:56,  1.76s/it]








 16%|█▌        | 130/834 [03:45<20:45,  1.77s/it]









 17%|█▋        | 140/834 [04:03<20:46,  1.80s/it]








 18%|█▊        | 150/834 [04:20<18:41,  1.64s/it]









 19%|█▉        | 160/834 [04:37<18:24,  1.64s/it]








 20%|██        | 170/834 [04:54<18:23,  1.66s/it]









 22%|██▏       | 180/834 [05:11<18:32,  1.70s/it]








 23%|██▎       | 189/834 [05:27<18:56,  1.76s/it]









 24%|██▍       | 200/834 [05:46<18:31,  1.75s/it]








 25%|██▌       | 209/834 [06:01<18:10,  1.75s/it]









 26%|██▋       | 219/834 [06:19<18:14,  1.78s/it]









 28%|██▊       | 230/834 [06:38<17:10,  1.71s/it]









 29%|██▉       | 240/834 [06:55<17:41,  1.79s/it]








 30%|██▉       | 250/834 [07:12<15:17,  1.57s/it]









 31%|███       | 260/834 [07:30<16:23,  1.71s/it]









 32%|███▏      | 270/834 [07:48<16:55,  1.80s/it]








 33%|███▎      | 279/834 [08:03<16:03,  1.74s/it]









 35%|███▍      | 290/834 [08:22<14:41,  1.62s/it]









 36%|███▌      | 300/834 [08:39<15:08,  1.70s/it]








 37%|███▋      | 309/834 [08:55<15:08,  1.73s/it]









 38%|███▊      | 320/834 [09:13<14:02,  1.64s/it]



 39%|███▉      | 324/834 [09:20<14:33,  1.71s/it]c:\ml_proj\tink_stag\.venv\Lib\site-packages\trl\trainer\reward_trainer.py:175: UserWarning: When using RewardDataCollatorWithPadding, you should set `max_length` in RewardConfig. It will be set to `512` by default, but you should do it yourself in the future.
  warnings.warn(
 39%|███▉      | 324/834 [16:45<26:22,  3.10s/it]
  0%|          | 0/750 [00:00<?, ?it/s]c:\ml_proj\tink_stag\.venv\Lib\site-packages\transformers\tokenization_utils_base.py:2906: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
  warnings.warn(
c:\ml_proj\tink_stag\.venv\Lib\site-packages\torch\utils\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(







  1%|          | 9/750 [00:15<21:30,  1.74s/it]









  3%|▎         | 20/750 [00:34<19:52,  1.63s/it]








  4%|▍         | 29/750 [00:49<20:27,  1.70s/it]









  5%|▌         | 40/750 [01:08<20:32,  1.74s/it]









  7%|▋         | 50/750 [01:26<21:09,  1.81s/it]








  8%|▊         | 59/750 [01:41<19:13,  1.67s/it]









  9%|▉         | 70/750 [02:00<19:50,  1.75s/it]









 11%|█         | 80/750 [02:18<19:04,  1.71s/it]








 12%|█▏        | 89/750 [02:33<19:13,  1.74s/it]









 13%|█▎        | 100/750 [02:52<18:46,  1.73s/it]








 15%|█▍        | 109/750 [03:07<17:30,  1.64s/it]









 16%|█▌        | 119/750 [03:26<19:14,  1.83s/it]









 17%|█▋        | 129/750 [03:43<17:54,  1.73s/it]









 19%|█▊        | 139/750 [04:01<17:51,  1.75s/it]









 20%|██        | 150/750 [04:20<17:00,  1.70s/it]









 21%|██▏       | 160/750 [04:38<17:11,  1.75s/it]








 23%|██▎       | 170/750 [04:55<15:58,  1.65s/it]








 24%|██▍       | 179/750 [05:10<15:24,  1.62s/it]









 25%|██▌       | 190/750 [05:28<14:58,  1.61s/it]









 27%|██▋       | 200/750 [05:46<16:34,  1.81s/it]









 28%|██▊       | 210/750 [06:04<14:57,  1.66s/it]








 29%|██▉       | 220/750 [06:21<15:04,  1.71s/it]









 31%|███       | 230/750 [06:38<14:53,  1.72s/it]









 32%|███▏      | 240/750 [06:56<14:46,  1.74s/it]








 33%|███▎      | 250/750 [07:13<14:05,  1.69s/it]









 35%|███▍      | 260/750 [07:30<13:58,  1.71s/it]








 36%|███▌      | 270/750 [07:47<13:40,  1.71s/it]









 37%|███▋      | 280/750 [08:05<14:03,  1.79s/it]









 39%|███▊      | 290/750 [08:22<12:57,  1.69s/it]








 40%|████      | 300/750 [08:39<13:09,  1.76s/it]









 41%|████▏     | 310/750 [08:56<12:23,  1.69s/it]









 43%|████▎     | 320/750 [09:14<12:28,  1.74s/it]









 44%|████▍     | 330/750 [09:32<12:27,  1.78s/it]








 45%|████▌     | 340/750 [09:49<11:42,  1.71s/it]









 47%|████▋     | 350/750 [10:06<11:08,  1.67s/it]








 48%|████▊     | 360/750 [10:22<10:59,  1.69s/it]








 49%|████▉     | 370/750 [10:38<10:31,  1.66s/it]








 51%|█████     | 380/750 [10:55<10:24,  1.69s/it]








 52%|█████▏    | 389/750 [11:10<10:11,  1.70s/it]








 53%|█████▎    | 399/750 [11:26<09:33,  1.63s/it]









 55%|█████▍    | 410/750 [11:44<09:41,  1.71s/it]








 56%|█████▌    | 420/750 [12:01<09:21,  1.70s/it]









 57%|█████▋    | 430/750 [12:18<08:35,  1.61s/it]








 59%|█████▊    | 440/750 [12:34<08:05,  1.57s/it]









 60%|██████    | 451/750 [12:53<08:34,  1.72s/it]








 61%|██████▏   | 460/750 [13:08<08:14,  1.70s/it]








 63%|██████▎   | 470/750 [13:25<07:51,  1.68s/it]









 64%|██████▍   | 480/750 [13:43<07:31,  1.67s/it]









 65%|██████▌   | 490/750 [14:00<07:41,  1.78s/it]








 67%|██████▋   | 500/750 [14:18<07:13,  1.73s/it]c:\ml_proj\tink_stag\.venv\Lib\site-packages\transformers\tokenization_utils_base.py:2906: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
  warnings.warn(
c:\ml_proj\tink_stag\.venv\Lib\site-packages\torch\utils\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 0.0133, 'grad_norm': 0.14556530117988586, 'learning_rate': 4.7e-06, 'epoch': 2.0}








 68%|██████▊   | 510/750 [14:36<07:08,  1.79s/it]








 69%|██████▉   | 520/750 [14:53<06:29,  1.69s/it]









 71%|███████   | 530/750 [15:11<06:21,  1.74s/it]









 72%|███████▏  | 540/750 [15:29<06:16,  1.79s/it]









 73%|███████▎  | 551/750 [15:48<05:46,  1.74s/it]








 75%|███████▍  | 560/750 [16:03<05:40,  1.79s/it]








 76%|███████▌  | 570/750 [16:21<05:05,  1.70s/it]









 77%|███████▋  | 580/750 [16:38<04:57,  1.75s/it]









 79%|███████▊  | 590/750 [16:56<04:28,  1.68s/it]








 80%|███████▉  | 599/750 [17:12<04:28,  1.78s/it]









 81%|████████▏ | 610/750 [17:31<03:45,  1.61s/it]








 83%|████████▎ | 620/750 [17:47<03:42,  1.71s/it]









 84%|████████▍ | 630/750 [18:05<03:22,  1.68s/it]








 85%|████████▌ | 639/750 [18:20<03:16,  1.77s/it]









 87%|████████▋ | 650/750 [18:39<02:46,  1.67s/it]









 88%|████████▊ | 661/750 [18:58<02:31,  1.71s/it]








 89%|████████▉ | 670/750 [19:13<02:16,  1.71s/it]









 91%|█████████ | 682/750 [19:34<01:58,  1.74s/it]







 92%|█████████▏| 690/750 [19:48<01:44,  1.73s/it]








 93%|█████████▎| 700/750 [20:05<01:26,  1.72s/it]









 95%|█████████▍| 710/750 [20:22<01:06,  1.66s/it]








 96%|█████████▌| 720/750 [20:38<00:49,  1.64s/it]








 97%|█████████▋| 730/750 [20:55<00:32,  1.64s/it]









 99%|█████████▉| 741/750 [21:13<00:14,  1.61s/it]








100%|██████████| 750/750 [21:28<00:00,  1.69s/it]

100%|██████████| 750/750 [21:32<00:00,  1.72s/it]
{'train_runtime': 1292.1564, 'train_samples_per_second': 18.576, 'train_steps_per_second': 0.58, 'train_loss': 0.027654054552316665, 'epoch': 2.99}
c:\ml_proj\tink_stag\.venv\Lib\site-packages\torch\utils\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
c:\ml_proj\tink_stag\.venv\Lib\site-packages\torch\utils\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
c:\ml_proj\tink_stag\.venv\Lib\site-packages\torch\utils\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
