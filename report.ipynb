{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ml_proj\\tink_stag\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset, load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "from WARPTrainer import WARPTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(\"imdb\", split=\"train\")\n",
    "raw_datasets = raw_datasets['text'][:24960]\n",
    "raw_datasets = Dataset.from_dict({\"query\": raw_datasets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PPOConfig(\n",
    "    model_name=\"lvwerra/gpt2-imdb\",\n",
    "    learning_rate=1.41e-5,\n",
    "    remove_unused_columns=False,\n",
    "    batch_size = 128,\n",
    "    kl_penalty = \"mse\"\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/24960 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Map: 100%|██████████| 24960/24960 [00:10<00:00, 2450.60 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(sample):\n",
    "    sample[\"input_ids\"] = tokenizer.encode(sample[\"query\"])\n",
    "    return sample\n",
    "\n",
    "raw_datasets = raw_datasets.map(tokenize, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 24960/24960 [00:02<00:00, 9256.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "        new_examples = {\n",
    "            \"input_ids\": [],\n",
    "            \"query\": [],\n",
    "        }\n",
    "\n",
    "       \n",
    "        \n",
    "        new_examples[\"input_ids\"] = examples[\"input_ids\"][:15]\n",
    "        new_examples[\"query\"] = tokenizer.decode(examples[\"input_ids\"][:15])\n",
    "            \n",
    "                \n",
    "        return new_examples\n",
    "\n",
    "datasets = raw_datasets.map(preprocess_function, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I rented I AM CURIOUS-YELLOW from my video store',\n",
       " '\"I Am Curious: Yellow\" is a risible and pretentious ste',\n",
       " 'If only to avoid making this type of film in the future. This film',\n",
       " \"This film was probably inspired by Godard's Masculin, fé\",\n",
       " 'Oh, brother...after hearing about this ridiculous film for umpteen years']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"query\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 24960/24960 [00:00<00:00, 187671.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "datasets = datasets.filter(\n",
    "    lambda x: len(x[\"input_ids\"]) == 15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.set_format(\"pytorch\")\n",
    "dataloader = DataLoader(datasets, batch_size= 128, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = WARPTrainer(\n",
    "    model=model,\n",
    "    ref_model=ref_model,\n",
    "    config=config,\n",
    "    dataset=datasets,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Параметры для генерации ответов моделью\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка предварительно обученой модели вознаграждения и создание pipeline\n",
    "r_model = AutoModelForSequenceClassification.from_pretrained(\"reward_model\", config=AutoConfig.from_pretrained('reward_model/config.json'))\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", model=r_model, tokenizer=bert_tokenizer, device=\"cuda\")\n",
    "sent_kwargs = {\"return_all_scores\": True, \"function_to_apply\": \"none\", \"batch_size\": 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "c:\\ml_proj\\tink_stag\\.venv\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:544: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "c:\\ml_proj\\tink_stag\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "10it [03:18, 20.50s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "195it [1:36:32, 29.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size (128) does not match number of examples - but got 126 for: queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Основной цикл дообучения на батчах данных\n",
    "\n",
    "\n",
    "output_min_length = 4\n",
    "output_max_length = 16\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}\n",
    "\n",
    "all_stats = []\n",
    "for epoch, batch in tqdm(enumerate(dataloader)):\n",
    "    query_tensors = batch[\"input_ids\"]\n",
    "    \n",
    "    \n",
    "    #### Get response from gpt2\n",
    "    response_tensors = []\n",
    "    query_tensors_l = []\n",
    "    for query in query_tensors:\n",
    "        query_tensors_l.append(query)\n",
    "        gen_len = output_length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "        response = trainer.generate(query.to(\"cuda\"), **generation_kwargs)\n",
    "        response_tensors.append(response.squeeze()[-gen_len:])\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "    \n",
    "\n",
    "    #### Compute sentiment score\n",
    "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
    "    \n",
    "    rewards = [torch.tensor(output[0][\"score\"]) for output in pipe_outputs]\n",
    "    \n",
    "\n",
    "    #### Run step\n",
    "    try:\n",
    "        stats = trainer.step(query_tensors_l, response_tensors, rewards)\n",
    "        all_stats.append(stats)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = {\"min_length\": -1, \"top_k\": 0.0, \"top_p\": 1.0, \"do_sample\": True, \"pad_token_id\": tokenizer.eos_token_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response (before)</th>\n",
       "      <th>response (after)</th>\n",
       "      <th>rewards (before)</th>\n",
       "      <th>rewards (after)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this show is one of the worst shows of ALL TIM...</td>\n",
       "      <td>ity throughout the film</td>\n",
       "      <td>OK OK OK OK</td>\n",
       "      <td>6.707960</td>\n",
       "      <td>6.590818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sure this movie is not historically accurate b...</td>\n",
       "      <td>pp's OK OK</td>\n",
       "      <td>OK OK OK OK</td>\n",
       "      <td>-6.718466</td>\n",
       "      <td>-6.616941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mild Spoilers&lt;br /&gt;&lt;br /&gt;In the near future</td>\n",
       "      <td>that Spike Lee does OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK</td>\n",
       "      <td>1.133858</td>\n",
       "      <td>0.825365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've seen some very terrible horror movies in ...</td>\n",
       "      <td>was OK OK OK</td>\n",
       "      <td>OK OK OK OK</td>\n",
       "      <td>-0.448612</td>\n",
       "      <td>-0.953155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For anyone who has only seen Disney Production...</td>\n",
       "      <td>and the Beast' OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>-2.353873</td>\n",
       "      <td>-2.755658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This is the touching story of two families in ...</td>\n",
       "      <td>of them are OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>-6.118678</td>\n",
       "      <td>-6.125435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The spoilers in this review are offered as a p...</td>\n",
       "      <td>person watching the movie had done OK OK OK O...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>2.192267</td>\n",
       "      <td>0.971499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>So this made for TV film scores only a 7.6 on ...</td>\n",
       "      <td>, OK OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>0.895894</td>\n",
       "      <td>0.821184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This movie is very cool. If you're a fan of Ts...</td>\n",
       "      <td>ark having Luke Skywalker canon about to work ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>-5.120286</td>\n",
       "      <td>-5.487232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Frankly I don't understand why this movie has ...</td>\n",
       "      <td>budget OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>1.117311</td>\n",
       "      <td>0.125291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>THE NOTORIOUS BETTIE PAGE (2006) ***1/</td>\n",
       "      <td>2 OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK</td>\n",
       "      <td>0.645659</td>\n",
       "      <td>0.559651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I never thought I see a movie worse than \"Lisa...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>0.861595</td>\n",
       "      <td>0.861595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I can count (on one hand) the number of good m...</td>\n",
       "      <td>Lawrence, King Kong, and OK</td>\n",
       "      <td>OK OK OK OK OK OK OK</td>\n",
       "      <td>-3.003966</td>\n",
       "      <td>-2.447529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This movie is very much like \"Flashdance\", you...</td>\n",
       "      <td>is OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>-3.400623</td>\n",
       "      <td>-3.345052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Why did I enjoy the show to the last episode? ...</td>\n",
       "      <td>nature of the mystery</td>\n",
       "      <td>OK OK OK OK</td>\n",
       "      <td>-1.659451</td>\n",
       "      <td>-0.829764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Having just seen the A Perfect Spy mini series...</td>\n",
       "      <td>see OK OK OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>-2.236291</td>\n",
       "      <td>-2.368044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0   this show is one of the worst shows of ALL TIM...   \n",
       "1   Sure this movie is not historically accurate b...   \n",
       "2         Mild Spoilers<br /><br />In the near future   \n",
       "3   I've seen some very terrible horror movies in ...   \n",
       "4   For anyone who has only seen Disney Production...   \n",
       "5   This is the touching story of two families in ...   \n",
       "6   The spoilers in this review are offered as a p...   \n",
       "7   So this made for TV film scores only a 7.6 on ...   \n",
       "8   This movie is very cool. If you're a fan of Ts...   \n",
       "9   Frankly I don't understand why this movie has ...   \n",
       "10             THE NOTORIOUS BETTIE PAGE (2006) ***1/   \n",
       "11  I never thought I see a movie worse than \"Lisa...   \n",
       "12  I can count (on one hand) the number of good m...   \n",
       "13  This movie is very much like \"Flashdance\", you...   \n",
       "14  Why did I enjoy the show to the last episode? ...   \n",
       "15  Having just seen the A Perfect Spy mini series...   \n",
       "\n",
       "                                    response (before)  \\\n",
       "0                             ity throughout the film   \n",
       "1                                          pp's OK OK   \n",
       "2                     that Spike Lee does OK OK OK OK   \n",
       "3                                        was OK OK OK   \n",
       "4                       and the Beast' OK OK OK OK OK   \n",
       "5                 of them are OK OK OK OK OK OK OK OK   \n",
       "6    person watching the movie had done OK OK OK O...   \n",
       "7               , OK OK OK OK OK OK OK OK OK OK OK OK   \n",
       "8   ark having Luke Skywalker canon about to work ...   \n",
       "9                      budget OK OK OK OK OK OK OK OK   \n",
       "10                             2 OK OK OK OK OK OK OK   \n",
       "11                   OK OK OK OK OK OK OK OK OK OK OK   \n",
       "12                        Lawrence, King Kong, and OK   \n",
       "13                is OK OK OK OK OK OK OK OK OK OK OK   \n",
       "14                              nature of the mystery   \n",
       "15         see OK OK OK OK OK OK OK OK OK OK OK OK OK   \n",
       "\n",
       "                              response (after)  rewards (before)  \\\n",
       "0                                  OK OK OK OK          6.707960   \n",
       "1                                  OK OK OK OK         -6.718466   \n",
       "2                      OK OK OK OK OK OK OK OK          1.133858   \n",
       "3                                  OK OK OK OK         -0.448612   \n",
       "4                   OK OK OK OK OK OK OK OK OK         -2.353873   \n",
       "5             OK OK OK OK OK OK OK OK OK OK OK         -6.118678   \n",
       "6    OK OK OK OK OK OK OK OK OK OK OK OK OK OK          2.192267   \n",
       "7       OK OK OK OK OK OK OK OK OK OK OK OK OK          0.895894   \n",
       "8          OK OK OK OK OK OK OK OK OK OK OK OK         -5.120286   \n",
       "9                   OK OK OK OK OK OK OK OK OK          1.117311   \n",
       "10                     OK OK OK OK OK OK OK OK          0.645659   \n",
       "11            OK OK OK OK OK OK OK OK OK OK OK          0.861595   \n",
       "12                        OK OK OK OK OK OK OK         -3.003966   \n",
       "13         OK OK OK OK OK OK OK OK OK OK OK OK         -3.400623   \n",
       "14                                 OK OK OK OK         -1.659451   \n",
       "15   OK OK OK OK OK OK OK OK OK OK OK OK OK OK         -2.236291   \n",
       "\n",
       "    rewards (after)  \n",
       "0          6.590818  \n",
       "1         -6.616941  \n",
       "2          0.825365  \n",
       "3         -0.953155  \n",
       "4         -2.755658  \n",
       "5         -6.125435  \n",
       "6          0.971499  \n",
       "7          0.821184  \n",
       "8         -5.487232  \n",
       "9          0.125291  \n",
       "10         0.559651  \n",
       "11         0.861595  \n",
       "12        -2.447529  \n",
       "13        -3.345052  \n",
       "14        -0.829764  \n",
       "15        -2.368044  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 16\n",
    "data = dict()\n",
    "datasets.set_format(\"pandas\")\n",
    "df_batch = datasets[:].sample(bs)\n",
    "data[\"query\"] = df_batch[\"query\"].tolist()\n",
    "query_tensors = df_batch[\"input_ids\"].tolist()\n",
    "\n",
    "response_tensors_ref, response_tensors = [], []\n",
    "\n",
    "#### get response from gpt2 and gpt2_ref\n",
    "for i in range(bs):\n",
    "    gen_len = output_length_sampler()\n",
    "    output = ref_model.generate(\n",
    "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(\"cuda\"), max_new_tokens=gen_len, **gen_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors_ref.append(output)\n",
    "    output = model.generate(\n",
    "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(\"cuda\"), max_new_tokens=gen_len, **gen_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    response_tensors.append(output)\n",
    "\n",
    "#### decode responses\n",
    "data[\"response (before)\"] = [tokenizer.decode(response_tensors_ref[i]) for i in range(bs)]\n",
    "data[\"response (after)\"] = [tokenizer.decode(response_tensors[i]) for i in range(bs)]\n",
    "\n",
    "#### sentiment analysis of query/response pairs before/after\n",
    "texts = [q + r for q, r in zip(data[\"query\"], data[\"response (before)\"])]\n",
    "\n",
    "data[\"rewards (before)\"] = [output[0][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
    "\n",
    "texts = [q + r for q, r in zip(data[\"query\"], data[\"response (after)\"])]\n",
    "data[\"rewards (after)\"] = [output[0][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
    "\n",
    "# store results in a dataframe\n",
    "df_results = pd.DataFrame(data)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rewards (before)   -1.094106\n",
       "rewards (after)    -1.260838\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "median:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rewards (before)   -1.054031\n",
       "rewards (after)    -0.891460\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"mean:\")\n",
    "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].mean())\n",
    "print()\n",
    "print(\"median:\")\n",
    "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlhf-njSEODfs-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
